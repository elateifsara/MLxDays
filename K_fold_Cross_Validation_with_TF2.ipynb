{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K-fold Cross Validation with TF2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBqpqjSZHDYpSRDbQTkPNH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elateifsara/MLxDays/blob/master/K_fold_Cross_Validation_with_TF2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYlBx4fc6AOs"
      },
      "source": [
        "Taken from : https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/#full-model-code\n",
        "\n",
        "We call this simple hold-out split, as we simply ‚Äúhold out‚Äù the last 2.000 samples (Chollet, 2017).\n",
        "\n",
        "It can be a highly effective approach. What‚Äôs more, it‚Äôs also very inexpensive in terms of the computational power you need. However, it‚Äôs also a very na√Øve approach, as you‚Äôll have to keep these edge cases in mind all the time (Chollet, 2017):\n",
        "\n",
        "Data representativeness: all datasets, which are essentially samples, must represent the patterns in the population as much as possible. This becomes especially important when you generate samples from a sample (i.e., from your full dataset). For example, if the first part of your dataset has pictures of ice cream, while the latter one only represents espressos, trouble is guaranteed when you generate the split as displayed above. Random shuffling may help you solve these issues.\n",
        "The arrow of time: if you have a time series dataset, your dataset is likely ordered chronologically. If you‚Äôd shuffle randomly, and then perform simple hold-out validation, you‚Äôd effectively ‚Äú[predict] the future given the past‚Äù (Chollet, 2017). Such temporal leaks don‚Äôt benefit model performance.\n",
        "Data redundancy: if some samples appear more than once, a simple hold-out split with random shuffling may introduce redundancy between training and testing datasets. That is, identical samples belong to both datasets. This is problematic too, as data used for training thus leaks into the dataset for testing implicitly.\n",
        "Now, as we can see, while a simple hold-out split based approach can be effective and will be efficient in terms of computational resources, it also requires you to monitor for these edge cases continuously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALkGAT0wqnhg"
      },
      "source": [
        "**K-fold Cross Validation**\n",
        "\n",
        "A more expensive and less na√Øve approach would be to perform K-fold Cross Validation. Here, you set some value for ùêæ and the dataset is split into ùêæ partitions of equal size. ùêæ‚Äì1 are used for training, while one is used for testing. This process is repeated ùêæ times, with a different partition used for testing each time.\n",
        "\n",
        "For example, this would be the scenario for our dataset with ùêæ=5 (i.e., once again the 80/20 split, but then 5 times!).\n",
        "\n",
        "For each split, the same model is trained, and performance is displayed per fold. For evaluation purposes, you can obviously also average it across all folds. While this produces better estimates, K-fold Cross Validation also increases training cost: in the ùêæ=5 scenario above, the model must be trained for 5 times.\n",
        "\n",
        "Let‚Äôs now extend our viewpoint with a few variations of K-fold Cross Validation üôÇ\n",
        "\n",
        "If you have no computational limitations whatsoever, you might wish to try a special case of K-fold Cross Validation, called Leave One Out Cross Validation (or LOOCV, Khandelwal 2019). LOOCV means ùêæ=ùëÅ, where ùëÅ is the number of samples in your dataset. As the number of models trained is maximized, the precision of the model performance average is maximized too, but so is the cost of training due to the sheer amount of models that must be trained.\n",
        "\n",
        "If you have a binary classification problem, you might also wish to take a look at Stratified Cross Validation (Khandelwal, 2019). It extends K-fold Cross Validation by ensuring an equal distribution of the target classes over the splits. This ensures that your classification problem is balanced. It doesn‚Äôt work for multiclass classification due to the way that samples are distributed.\n",
        "\n",
        "Finally, if you have a time series dataset, you might wish to use Time-series Cross Validation (Khandelwal, 2019). [Check here how it works](https://medium.com/datadriveninvestor/k-fold-and-other-cross-validation-techniques-6c03a2563f1e#4a74)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMHpyfPtt9j"
      },
      "source": [
        "**Creating a Keras model with K-fold Cross Validation**\n",
        "\n",
        "Now that we understand how K-fold Cross Validation works, it‚Äôs time to code an example with the Keras deep learning framework üôÇ\n",
        "\n",
        "Coding it will be a multi-stage process:\n",
        "\n",
        "* Firstly, we‚Äôll take a look at what we need in order to run our model successfully.\n",
        "* Then, we take a look at today‚Äôs model.\n",
        "* Subsequently, we add K-fold Cross Validation, train the model instances, and average performance.\n",
        "* Finally, we output the performance metrics on screen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iemDlMXs1oPP",
        "outputId": "ba16097e-1f74-4b2d-ee42-a2c526995d59"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Model configuration\n",
        "batch_size = 50\n",
        "img_width, img_height, img_num_channels = 32, 32, 3\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 100\n",
        "no_epochs = 25\n",
        "optimizer = Adam()\n",
        "verbosity = 1\n",
        "num_folds = 10\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
        "\n",
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=loss_function,\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 36s 3ms/step - loss: 1.8356 - accuracy: 0.3519\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1326 - accuracy: 0.6016\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9549 - accuracy: 0.6659\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8234 - accuracy: 0.7131\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7109 - accuracy: 0.7515\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6256 - accuracy: 0.7816\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5340 - accuracy: 0.8138\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4528 - accuracy: 0.8416\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3729 - accuracy: 0.8685\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3109 - accuracy: 0.8918\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2466 - accuracy: 0.9149\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2043 - accuracy: 0.9287\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1725 - accuracy: 0.9396\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1364 - accuracy: 0.9537\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1220 - accuracy: 0.9564\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1127 - accuracy: 0.9611\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1011 - accuracy: 0.9648\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1003 - accuracy: 0.9654\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.9711\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0815 - accuracy: 0.9721\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0695 - accuracy: 0.9757\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0693 - accuracy: 0.9763\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0788 - accuracy: 0.9730\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0631 - accuracy: 0.9782\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0683 - accuracy: 0.9764\n",
            "Score for fold 1: loss of 2.110980272293091; accuracy of 71.21666669845581%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.8617 - accuracy: 0.3278\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.2050 - accuracy: 0.5697\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.0297 - accuracy: 0.6353\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9399 - accuracy: 0.6682\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8713 - accuracy: 0.6943\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8045 - accuracy: 0.7177\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7567 - accuracy: 0.7343\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7174 - accuracy: 0.7463\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6683 - accuracy: 0.7654\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6334 - accuracy: 0.7771\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5966 - accuracy: 0.7897\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5581 - accuracy: 0.8021\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5237 - accuracy: 0.8149\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4935 - accuracy: 0.8279\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4646 - accuracy: 0.8352\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4336 - accuracy: 0.8465\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4166 - accuracy: 0.8533\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3758 - accuracy: 0.8670\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3554 - accuracy: 0.8738\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3295 - accuracy: 0.8835\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3180 - accuracy: 0.8874\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2835 - accuracy: 0.8999\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2714 - accuracy: 0.9048\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2535 - accuracy: 0.9118\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2372 - accuracy: 0.9170\n",
            "Score for fold 2: loss of 1.4682693481445312; accuracy of 67.88333058357239%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.7702 - accuracy: 0.3626\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1184 - accuracy: 0.6021\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9796 - accuracy: 0.6517\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8625 - accuracy: 0.6955\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7808 - accuracy: 0.7267\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7189 - accuracy: 0.7481\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6667 - accuracy: 0.7646\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6092 - accuracy: 0.7855\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5644 - accuracy: 0.8019\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5099 - accuracy: 0.8194\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4585 - accuracy: 0.8402\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4157 - accuracy: 0.8521\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3783 - accuracy: 0.8653\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3297 - accuracy: 0.8863\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3091 - accuracy: 0.8882\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2697 - accuracy: 0.9061\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2414 - accuracy: 0.9145\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2120 - accuracy: 0.9257\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1975 - accuracy: 0.9319\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1728 - accuracy: 0.9410\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1500 - accuracy: 0.9469\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1378 - accuracy: 0.9505\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1295 - accuracy: 0.9558\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1181 - accuracy: 0.9584\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1167 - accuracy: 0.9589\n",
            "Score for fold 3: loss of 2.0588715076446533; accuracy of 67.29999780654907%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.7434 - accuracy: 0.3759\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1152 - accuracy: 0.6044\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9631 - accuracy: 0.6571\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8623 - accuracy: 0.6946\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7856 - accuracy: 0.7248\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7230 - accuracy: 0.7493\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6602 - accuracy: 0.7691\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6122 - accuracy: 0.7864\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.5463 - accuracy: 0.8089\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4980 - accuracy: 0.8280\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4507 - accuracy: 0.8424\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4042 - accuracy: 0.8605\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3573 - accuracy: 0.8778\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3129 - accuracy: 0.8923\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2809 - accuracy: 0.9036\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2461 - accuracy: 0.9166\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2249 - accuracy: 0.9224\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1970 - accuracy: 0.9335\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1768 - accuracy: 0.9383\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1621 - accuracy: 0.9422\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1449 - accuracy: 0.9508\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1325 - accuracy: 0.9551\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1169 - accuracy: 0.9593\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1100 - accuracy: 0.9615\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1189 - accuracy: 0.9584\n",
            "Score for fold 4: loss of 2.0477893352508545; accuracy of 67.35000014305115%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 2.0005 - accuracy: 0.2806\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.3103 - accuracy: 0.5294\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1376 - accuracy: 0.5958\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.0202 - accuracy: 0.6386\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9393 - accuracy: 0.6699\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8779 - accuracy: 0.6935\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8255 - accuracy: 0.7114\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7718 - accuracy: 0.7292\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7278 - accuracy: 0.7468\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6892 - accuracy: 0.7591\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6564 - accuracy: 0.7689\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6212 - accuracy: 0.7830\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5886 - accuracy: 0.7932\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5610 - accuracy: 0.8028\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5237 - accuracy: 0.8165\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5043 - accuracy: 0.8213\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4763 - accuracy: 0.8329\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4504 - accuracy: 0.8421\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4257 - accuracy: 0.8504\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4015 - accuracy: 0.8590\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3802 - accuracy: 0.8649\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3492 - accuracy: 0.8780\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.3320 - accuracy: 0.8832\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3094 - accuracy: 0.8906\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2908 - accuracy: 0.8970\n",
            "Score for fold 5: loss of 1.357312560081482; accuracy of 67.96666383743286%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.8813 - accuracy: 0.3155\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.2923 - accuracy: 0.5320\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.0955 - accuracy: 0.6082\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9955 - accuracy: 0.6508\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9022 - accuracy: 0.6848\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8291 - accuracy: 0.7065\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7787 - accuracy: 0.7285\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7345 - accuracy: 0.7400\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6898 - accuracy: 0.7580\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6359 - accuracy: 0.7771\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6051 - accuracy: 0.7859\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5726 - accuracy: 0.8007\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5262 - accuracy: 0.8131\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4757 - accuracy: 0.8341\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4494 - accuracy: 0.8440\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4216 - accuracy: 0.8510\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3834 - accuracy: 0.8670\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3573 - accuracy: 0.8730\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3272 - accuracy: 0.8849\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2983 - accuracy: 0.8955\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2758 - accuracy: 0.9032\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2529 - accuracy: 0.9128\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2345 - accuracy: 0.9175\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2150 - accuracy: 0.9243\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1909 - accuracy: 0.9331\n",
            "Score for fold 6: loss of 1.6407026052474976; accuracy of 67.04999804496765%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.9842 - accuracy: 0.2809\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.2896 - accuracy: 0.5361\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1094 - accuracy: 0.6076\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.0068 - accuracy: 0.6421\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9234 - accuracy: 0.6752\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8473 - accuracy: 0.6999\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7915 - accuracy: 0.7233\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7337 - accuracy: 0.7426\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6839 - accuracy: 0.7585\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6475 - accuracy: 0.7730\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5948 - accuracy: 0.7910\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5479 - accuracy: 0.8073\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5073 - accuracy: 0.8235\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4663 - accuracy: 0.8372\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4282 - accuracy: 0.8493\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3901 - accuracy: 0.8640\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3533 - accuracy: 0.8767\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3279 - accuracy: 0.8831\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2970 - accuracy: 0.8975\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2724 - accuracy: 0.9043\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2493 - accuracy: 0.9135\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2250 - accuracy: 0.9218\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2053 - accuracy: 0.9279\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.1817 - accuracy: 0.9382\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1773 - accuracy: 0.9388\n",
            "Score for fold 7: loss of 1.944441556930542; accuracy of 64.93333578109741%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.7689 - accuracy: 0.3549\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1266 - accuracy: 0.5963\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9461 - accuracy: 0.6686\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8261 - accuracy: 0.7116\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7535 - accuracy: 0.7366\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6846 - accuracy: 0.7609\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6273 - accuracy: 0.7780\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5706 - accuracy: 0.7989\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5186 - accuracy: 0.8188\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4676 - accuracy: 0.8359\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4270 - accuracy: 0.8481\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3767 - accuracy: 0.8714\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3338 - accuracy: 0.8818\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3018 - accuracy: 0.8951\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2667 - accuracy: 0.9063\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2311 - accuracy: 0.9201\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2112 - accuracy: 0.9272\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1786 - accuracy: 0.9383\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1606 - accuracy: 0.9441\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1528 - accuracy: 0.9467\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1341 - accuracy: 0.9528\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1191 - accuracy: 0.9593\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1124 - accuracy: 0.9605\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1116 - accuracy: 0.9604\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0972 - accuracy: 0.9663\n",
            "Score for fold 8: loss of 2.190190553665161; accuracy of 67.08333492279053%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.7902 - accuracy: 0.3544\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1115 - accuracy: 0.6055\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9515 - accuracy: 0.6657\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8531 - accuracy: 0.7001\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7551 - accuracy: 0.7363\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6808 - accuracy: 0.7606\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5958 - accuracy: 0.7892\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5330 - accuracy: 0.8121\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4678 - accuracy: 0.8371\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.4122 - accuracy: 0.8573\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3528 - accuracy: 0.8758\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3082 - accuracy: 0.8908\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.2576 - accuracy: 0.9098\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2275 - accuracy: 0.9212\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2009 - accuracy: 0.9290\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1718 - accuracy: 0.9381\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1620 - accuracy: 0.9414\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1284 - accuracy: 0.9558\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1210 - accuracy: 0.9580\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.1045 - accuracy: 0.9652\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0913 - accuracy: 0.9678\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0959 - accuracy: 0.9672\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.0871 - accuracy: 0.9698\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0829 - accuracy: 0.9707\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.0700 - accuracy: 0.9757\n",
            "Score for fold 9: loss of 2.438352108001709; accuracy of 67.2166645526886%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 1.9807 - accuracy: 0.2781\n",
            "Epoch 2/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.2766 - accuracy: 0.5432\n",
            "Epoch 3/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.1050 - accuracy: 0.6087\n",
            "Epoch 4/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 1.0119 - accuracy: 0.6407\n",
            "Epoch 5/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.9359 - accuracy: 0.6704\n",
            "Epoch 6/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8731 - accuracy: 0.6889\n",
            "Epoch 7/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.8193 - accuracy: 0.7101\n",
            "Epoch 8/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7674 - accuracy: 0.7294\n",
            "Epoch 9/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.7324 - accuracy: 0.7437\n",
            "Epoch 10/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6918 - accuracy: 0.7550\n",
            "Epoch 11/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6532 - accuracy: 0.7721\n",
            "Epoch 12/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.6130 - accuracy: 0.7851\n",
            "Epoch 13/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5860 - accuracy: 0.7935\n",
            "Epoch 14/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5455 - accuracy: 0.8072\n",
            "Epoch 15/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.5158 - accuracy: 0.8177\n",
            "Epoch 16/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4903 - accuracy: 0.8291\n",
            "Epoch 17/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4517 - accuracy: 0.8415\n",
            "Epoch 18/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.4239 - accuracy: 0.8517\n",
            "Epoch 19/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3901 - accuracy: 0.8657\n",
            "Epoch 20/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3656 - accuracy: 0.8727\n",
            "Epoch 21/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3445 - accuracy: 0.8762\n",
            "Epoch 22/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3149 - accuracy: 0.8912\n",
            "Epoch 23/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.3005 - accuracy: 0.8939\n",
            "Epoch 24/25\n",
            "1080/1080 [==============================] - 3s 3ms/step - loss: 0.2672 - accuracy: 0.9071\n",
            "Epoch 25/25\n",
            "1080/1080 [==============================] - 4s 3ms/step - loss: 0.2483 - accuracy: 0.9134\n",
            "Score for fold 10: loss of 1.4333250522613525; accuracy of 67.33333468437195%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 2.110980272293091 - Accuracy: 71.21666669845581%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.4682693481445312 - Accuracy: 67.88333058357239%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 2.0588715076446533 - Accuracy: 67.29999780654907%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 2.0477893352508545 - Accuracy: 67.35000014305115%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.357312560081482 - Accuracy: 67.96666383743286%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 1.6407026052474976 - Accuracy: 67.04999804496765%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 1.944441556930542 - Accuracy: 64.93333578109741%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 2.190190553665161 - Accuracy: 67.08333492279053%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 2.438352108001709 - Accuracy: 67.2166645526886%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 1.4333250522613525 - Accuracy: 67.33333468437195%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 67.53333270549774 (+- 1.4595085482662336)\n",
            "> Loss: 1.8690234899520874\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRIYsTYFMPUC"
      },
      "source": [
        "Interesting to try without the K-Fold :\n",
        "- https://www.tensorflow.org/tutorials/structured_data/imbalanced_data [Check METRICS]\n",
        "- And the following 2 (down) : \n",
        "  - https://stackoverflow.com/questions/37657260/how-to-implement-custom-metric-in-keras\n",
        "  - https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6a1MBbNFalb"
      },
      "source": [
        "import keras as keras\n",
        "import numpy as np\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "# ...\n",
        "sgd = SGD(lr=0.001, momentum=0.9)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "class Metrics(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self._data = []\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        X_val, y_val = self.validation_data[0], self.validation_data[1]\n",
        "        y_predict = np.asarray(model.predict(X_val))\n",
        "\n",
        "        y_val = np.argmax(y_val, axis=1)\n",
        "        y_predict = np.argmax(y_predict, axis=1)\n",
        "\n",
        "        self._data.append({\n",
        "            'val_rocauc': roc_auc_score(y_val, y_predict),\n",
        "        })\n",
        "        return\n",
        "\n",
        "    def get_data(self):\n",
        "        return self._data\n",
        "\n",
        "metrics = Metrics()\n",
        "#history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[metrics])\n",
        "#metrics.get_data()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1EplEPgzqAs"
      },
      "source": [
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "class Metrics(Callback):\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        " \n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
        "    val_targ = self.model.validation_data[1]\n",
        "    _val_f1 = f1_score(val_targ, val_predict)\n",
        "    _val_recall = recall_score(val_targ, val_predict)\n",
        "    _val_precision = precision_score(val_targ, val_predict)\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    #print(\"‚Äî val_f1: %f ‚Äî val_precision: %f ‚Äî val_recall %f\" %(_val_f1, _val_precision, _val_recall)\n",
        "    return\n",
        "  \n",
        "  def get_data(self):\n",
        "    return self.val_f1s, self.val_recalls, self.val_precisions\n",
        "\n",
        "metrics = Metrics()\n",
        "\n",
        "# Please call these in an no K-fold thing"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_Nm7yTKMuP_"
      },
      "source": [
        "# Coming back to K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDcjIpdZBr-E",
        "outputId": "4f88afea-e3e2-4d1a-a011-89db09edcef8"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "import sklearn\n",
        "from sklearn.preprocessing import binarize\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, plot_precision_recall_curve, f1_score, confusion_matrix\n",
        "\n",
        "# Model configuration\n",
        "batch_size = 50\n",
        "img_width, img_height, img_num_channels = 32, 32, 3\n",
        "loss_function = sparse_categorical_crossentropy\n",
        "no_classes = 100\n",
        "no_epochs = 2#25\n",
        "optimizer = Adam()\n",
        "verbosity = 1\n",
        "num_folds = 5\n",
        "\n",
        "# Load CIFAR-10 data\n",
        "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
        "\n",
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "predictions = []\n",
        "ground_truths = []\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=loss_function,\n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              verbose=verbosity)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  prediction = model.predict(inputs[test])\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  predictions.append(prediction)\n",
        "  ground_truths.append(targets[test])\n",
        "  \n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "#print(f'> F1-score: {np.mean(f1score_per_fold)} (+- {np.std(f1score_per_fold)})')\n",
        "#print(f'> F1-score: {np.mean(metrics.val_f1s)} (+- {np.std(metrics.val_f1s)})')\n",
        "#print(f'> Precision: {np.mean(metrics.val_precisions)} (+- {np.std(metrics.val_precisions)})')\n",
        "#print(f'> Precision: {np.mean(metrics.val_recalls)} (+- {np.std(metrics.val_recalls)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/2\n",
            "960/960 [==============================] - 4s 3ms/step - loss: 1.8786 - accuracy: 0.3401\n",
            "Epoch 2/2\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 1.1876 - accuracy: 0.5798\n",
            "Score for fold 1: loss of 1.0698779821395874; accuracy of 62.5249981880188%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/2\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 1.8136 - accuracy: 0.3442\n",
            "Epoch 2/2\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 1.1676 - accuracy: 0.5805\n",
            "Score for fold 2: loss of 1.0498671531677246; accuracy of 62.74999976158142%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/2\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 1.8373 - accuracy: 0.3376\n",
            "Epoch 2/2\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 1.1888 - accuracy: 0.5768\n",
            "Score for fold 3: loss of 1.1101101636886597; accuracy of 61.06666922569275%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/2\n",
            "960/960 [==============================] - 4s 3ms/step - loss: 1.8621 - accuracy: 0.3257\n",
            "Epoch 2/2\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 1.1653 - accuracy: 0.5870\n",
            "Score for fold 4: loss of 1.0562747716903687; accuracy of 62.63333559036255%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/2\n",
            "960/960 [==============================] - 4s 3ms/step - loss: 1.8257 - accuracy: 0.3416\n",
            "Epoch 2/2\n",
            "960/960 [==============================] - 3s 3ms/step - loss: 1.1753 - accuracy: 0.5838\n",
            "Score for fold 5: loss of 1.1280899047851562; accuracy of 60.45833230018616%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 1.0698779821395874 - Accuracy: 62.5249981880188%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 1.0498671531677246 - Accuracy: 62.74999976158142%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 1.1101101636886597 - Accuracy: 61.06666922569275%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 1.0562747716903687 - Accuracy: 62.63333559036255%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 1.1280899047851562 - Accuracy: 60.45833230018616%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 61.886667013168335 (+- 0.9405169335224576)\n",
            "> Loss: 1.0828439950942994\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-l7eyjz5M8R",
        "outputId": "8c690b1d-870b-4756-f63b-8ef917a0106c"
      },
      "source": [
        "len(predictions), len(ground_truths)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bw2q64M7RwM",
        "outputId": "f6abcb67-fcbe-443d-baf5-63fba1a89991"
      },
      "source": [
        "for elt1, elt2 in zip([1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0]):\n",
        "  #print(np.rint(np.max(elt1,axis=1)))\n",
        "  precision, recall, _ = precision_recall_curve([elt2], [elt1])\n",
        "  prec_per_fold.append(precision)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGxSHOp3HS0o"
      },
      "source": [
        "sens_per_fold = []\n",
        "spec_per_fold = []\n",
        "prec_per_fold = []\n",
        "auc_per_fold = []\n",
        "f1score_per_fold = []\n",
        "\n",
        "## ADD CALCULATION OF AUC + F1-SCORE + ROC + PRECISION + RECALL + SPECIFICTY + SENSITIVTY (and store these in df and save it + the model)\n",
        "  ## sensitivity == recall\n",
        "def calculate_metrics(t_y, t_p):\n",
        "  precision, recall, _ = precision_recall_curve(t_y,p_y)\n",
        "  prec_per_fold.append(precision)\n",
        "  sens_per_fold.append(recall)\n",
        "\n",
        "  fpr, tpr, _ = roc_curve(t_y,p_y)\n",
        "  auc = auc(fpr, tpr)\n",
        "  auc_per_fold.append(auc)\n",
        "\n",
        "  tn, fp, fn, tp = sklearn.metrics.confusion_matrix(t_y,p_y).ravel() \n",
        "  spec = tn/(tn+fp)\n",
        "  spec_per_fold.append(spec)\n",
        "\n",
        "  f1_score = 2*(precision*recall)/(precision+recall)\n",
        "  f1score_per_fold.append(f1_score)\n",
        "  return sens_per_fold, spec_per_fold, prec_per_fold, auc_per_fold, f1score_per_fold"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}